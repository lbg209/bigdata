{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 참조1: https://somjang.tistory.com/entry/Python-selenium%EA%B3%BC-BeautifulSoup%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%98%EC%97%AC-%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%89%B4%EC%8A%A4-%EA%B8%B0%EC%82%AC-%ED%81%AC%EB%A1%A4%EB%A7%81%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95\n","\n","### 참조2: https://aytekin.tistory.com/48\n","\n","### 참조3: https://book.coalastudy.com/data_crawling/week3/stage3"],"metadata":{"id":"DwBhRdzcWW5U"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mh8KBWMnUWmX","executionInfo":{"status":"ok","timestamp":1648695021920,"user_tz":-540,"elapsed":57824,"user":{"displayName":"이병규컴퓨터공학과","userId":"10470548857511681519"}},"outputId":"5b051483-405a-4e76-d56d-49eaf4cddfa1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n","\u001b[K     |████████████████████████████████| 968 kB 4.9 MB/s \n","\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 62.9 MB/s \n","\u001b[?25hCollecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Collecting trio~=0.17\n","  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n","\u001b[K     |████████████████████████████████| 359 kB 50.6 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n","Collecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Collecting outcome\n","  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n","Collecting async-generator>=1.9\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n","Collecting pyOpenSSL>=0.14\n","  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n","Collecting cryptography>=1.3.4\n","  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n","Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed async-generator-1.10 cryptography-36.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n","Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Err:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","  404  Not Found [IP: 152.195.19.142 443]\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [80.8 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [878 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,486 kB]\n","Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,678 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,830 kB]\n","Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [950 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,264 kB]\n","Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [911 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,117 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n","Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n","Reading package lists... Done\n","E: The repository 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release' no longer has a Release file.\n","N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n","N: See apt-secure(8) manpage for repository creation and user configuration details.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 81 not upgraded.\n","Need to get 88.3 MB of archives.\n","After this operation, 294 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 99.0.4844.84-0ubuntu0.18.04.1 [1,142 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 99.0.4844.84-0ubuntu0.18.04.1 [77.7 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 99.0.4844.84-0ubuntu0.18.04.1 [4,397 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 99.0.4844.84-0ubuntu0.18.04.1 [5,092 kB]\n","Fetched 88.3 MB in 2s (46.7 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 156210 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_99.0.4844.84-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (99.0.4844.84-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (99.0.4844.84-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"]}],"source":["#이 부분은 처음 한번만 실행하면 됌.\n","!pip install selenium\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","!pip install tqdm\n","!pip install bs4\n","!pip install lxml"]},{"cell_type":"code","source":["# -*- coding: UTF-8 -*-\n","import time\n","from selenium import webdriver as wd\n","from tqdm import tqdm\n","from datetime import datetime\n","import os\n"," \n","#Colab에선 웹브라우저 창이 뜨지 않으므로 별도 설정한다.\n"," \n","options = wd.ChromeOptions()\n","options.add_argument('--headless')        # Head-less 설정\n","options.add_argument('--no-sandbox')\n","options.add_argument('--disable-dev-shm-usage')\n","driver = wd.Chrome('chromedriver', options=options)\n"," \n","#해당 url로 이동\n","url = \"https://www.naver.com/\" \n","driver.get(url)\n"," \n","update = driver.find_element_by_css_selector('#NM_TS_ROLLING_WRAP > div > div')\n","print(update.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOUeC3osU0mj","executionInfo":{"status":"ok","timestamp":1648695057061,"user_tz":-540,"elapsed":4314,"user":{"displayName":"이병규컴퓨터공학과","userId":"10470548857511681519"}},"outputId":"f40bef8a-cca6-4600-a001-ca0d7e074a5f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["이슈\n","코로나바이러스감염증-19 현황\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n"]}]},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import urllib\n","\n","def get_article_info(driver, crawl_date, press_list, title_list, link_list, date_list, more_news_base_url=None, more_news=False):\n","    more_news_url_list = []\n","    while True:    \n","        page_html_source = driver.page_source\n","        url_soup = BeautifulSoup(page_html_source, 'lxml')\n","        \n","        more_news_infos = url_soup.select('a.news_more')\n","        \n","        if more_news:\n","            for more_news_info in more_news_infos:\n","                more_news_url = f\"{more_news_base_url}{more_news_info.get('href')}\"\n","\n","                more_news_url_list.append(more_news_url)\n","\n","        article_infos = url_soup.select(\"div.news_area\")\n","        \n","        if not article_infos:\n","            break\n","\n","        for article_info in article_infos:  \n","            press_info = article_info.select_one(\"div.info_group > a.info.press\")\n","            \n","            if press_info is None:\n","                press_info = article_info.select_one(\"div.info_group > span.info.press\")\n","            article = article_info.select_one(\"a.news_tit\")\n","            \n","            press = press_info.text.replace(\"언론사 선정\", \"\")\n","            title = article.get('title')\n","            link = article.get('href')\n","\n","#             print(f\"press - {press} / title - {title} / link - {link}\")\n","            press_list.append(press)\n","            title_list.append(title)\n","            link_list.append(link)\n","            date_list.append(crawl_date)\n","\n","        time.sleep(2.0)\n","                      \n","                      \n","        next_button_status = url_soup.select_one(\"a.btn_next\").get(\"aria-disabled\")\n","        \n","        if next_button_status == 'true':\n","            break\n","        \n","        time.sleep(1.0)\n","        next_page_btn = driver.find_element_by_css_selector(\"a.btn_next\").click()      \n","    \n","    return press_list, title_list, link_list, more_news_url_list\n","    \n","    \n","\n","def get_naver_news_info_from_selenium(keyword, save_path, target_date, ds_de, sort=0, remove_duplicate=False):\n","    crawl_date = f\"{target_date[:4]}.{target_date[4:6]}.{target_date[6:]}\"\n","    #driver = wd.Chrome(\"./chromedriver\") # chromedriver 파일 경로\n","    options = wd.ChromeOptions()\n","    options.add_argument('--headless')        # Head-less 설정\n","    options.add_argument('--no-sandbox')\n","    options.add_argument('--disable-dev-shm-usage')\n","    driver = wd.Chrome('chromedriver', options=options)\n","\n","    encoded_keyword = urllib.parse.quote(keyword)\n","    url = f\"https://search.naver.com/search.naver?where=news&query={encoded_keyword}&sm=tab_opt&sort={sort}&photo=0&field=0&pd=3&ds={ds_de}&de={ds_de}&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom{target_date}to{target_date}&is_sug_officeid=0\"\n","    \n","    more_news_base_url = \"https://search.naver.com/search.naver\"\n","\n","    driver.get(url)\n","    \n","    press_list, title_list, link_list, date_list, more_news_url_list = [], [], [], [], []\n","    \n","    press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n","                                                                             crawl_date=crawl_date, \n","                                                                             press_list=press_list, \n","                                                                             title_list=title_list, \n","                                                                             link_list=link_list,\n","                                                                             date_list=date_list,\n","                                                                             more_news_base_url=more_news_base_url,\n","                                                                             more_news=True)\n","    driver.close()\n","    \n","    if len(more_news_url_list) > 0:\n","        print(len(more_news_url_list))\n","        more_news_url_list = list(set(more_news_url_list))\n","        print(f\"->{len(more_news_url_list)}\")\n","        for more_news_url in more_news_url_list:\n","            driver = wd.Chrome(\"./chromedriver\")\n","            driver.get(more_news_url)\n","            \n","            press_list, title_list, link_list, more_news_url_list = get_article_info(driver=driver, \n","                                                                             crawl_date=crawl_date, \n","                                                                             press_list=press_list, \n","                                                                             title_list=title_list, \n","                                                                             link_list=link_list,\n","                                                                             date_list=date_list)\n","            driver.close()\n","    article_df = pd.DataFrame({\"날짜\": date_list, \"언론사\": press_list, \"제목\": title_list, \"링크\": link_list})\n","    \n","    print(f\"extract article num : {len(article_df)}\")\n","    if remove_duplicate:\n","        article_df = article_df.drop_duplicates(['링크'], keep='first')\n","        print(f\"after remove duplicate -> {len(article_df)}\")\n","    \n","    article_df.to_excel(save_path, index=False)"],"metadata":{"id":"pBRIbwSJUXJ-","executionInfo":{"status":"ok","timestamp":1648695062157,"user_tz":-540,"elapsed":910,"user":{"displayName":"이병규컴퓨터공학과","userId":"10470548857511681519"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def crawl_news_data(keyword, year, month, start_day, end_day, save_path):\n","    for day in tqdm(range(start_day, end_day+1)):\n","        date_time_obj = datetime(year=year, month=month, day=day)\n","        target_date = date_time_obj.strftime(\"%Y%m%d\")\n","        ds_de = date_time_obj.strftime(\"%Y.%m.%d\")\n","\n","        get_naver_news_info_from_selenium(keyword=keyword, save_path=f\"{save_path}/{keyword}/{target_date}_{keyword}_.xlsx\", target_date=target_date, ds_de=ds_de, remove_duplicate=False)"],"metadata":{"id":"wRy5qeL0UXnz","executionInfo":{"status":"ok","timestamp":1648695072184,"user_tz":-540,"elapsed":275,"user":{"displayName":"이병규컴퓨터공학과","userId":"10470548857511681519"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["keywords = ['틴더', '토스', '야놀자', '당근마켓', '아프리카tv', '온플법', '매치그룹']\n","save_path = \"./naver_news_article_2022\"\n","\n","for keyword in keywords:\n","    os.makedirs(f\"{save_path}/{keyword}\")"],"metadata":{"id":"1rlf8yDQVQG4","executionInfo":{"status":"error","timestamp":1648695458197,"user_tz":-540,"elapsed":277,"user":{"displayName":"이병규컴퓨터공학과","userId":"10470548857511681519"}},"colab":{"base_uri":"https://localhost:8080/","height":339},"outputId":"08665942-45e9-4673-e040-36dfb4a05be8"},"execution_count":9,"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-278f43e5a13d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{save_path}/{keyword}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './naver_news_article_2022/틴더'"]}]},{"cell_type":"code","source":["for keyword in keywords:\n","    print(f\"start keyword - {keyword} crawling ...\")\n","    crawl_news_data(keyword=keyword, year=2022, month=1, start_day=1, end_day=13, save_path=save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":877},"id":"1K3nec8hVdSR","executionInfo":{"status":"error","timestamp":1648695564111,"user_tz":-540,"elapsed":72355,"user":{"displayName":"이병규컴퓨터공학과","userId":"10470548857511681519"}},"outputId":"6445bae7-7390-4ca3-bdc7-e1115169ad76"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["start keyword - 틴더 crawling ...\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 1/13 [00:02<00:30,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 2/13 [00:04<00:25,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 3/13 [00:07<00:23,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 4/13 [00:11<00:29,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 3\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 5/13 [00:16<00:29,  3.66s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 2\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 6/13 [00:18<00:23,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 7/13 [00:22<00:21,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 8/13 [00:25<00:16,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 9/13 [00:29<00:14,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 10/13 [00:34<00:11,  3.90s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 2\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 11/13 [00:36<00:06,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 0\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 12/13 [00:41<00:03,  3.79s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:45<00:00,  3.53s/it]\n"]},{"output_type":"stream","name":"stdout","text":["extract article num : 1\n","start keyword - 토스 crawling ...\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n","  8%|▊         | 1/13 [00:08<01:44,  8.71s/it]"]},{"output_type":"stream","name":"stdout","text":["extract article num : 20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n","  8%|▊         | 1/13 [00:26<05:12, 26.02s/it]"]},{"output_type":"stream","name":"stdout","text":["2\n","->2\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"WebDriverException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             creationflags=self.creationflags)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './chromedriver': './chromedriver'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-6953ddae3426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"start keyword - {keyword} crawling ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcrawl_news_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_day\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_day\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-1a1533e2109f>\u001b[0m in \u001b[0;36mcrawl_news_data\u001b[0;34m(keyword, year, month, start_day, end_day, save_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mds_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_time_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y.%m.%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mget_naver_news_info_from_selenium\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{save_path}/{keyword}/{target_date}_{keyword}_.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_de\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-d1a56a31e4b6>\u001b[0m in \u001b[0;36mget_naver_news_info_from_selenium\u001b[0;34m(keyword, save_path, target_date, ds_de, sort, remove_duplicate)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"->{len(more_news_url_list)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmore_news_url\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmore_news_url_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./chromedriver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmore_news_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m                                         \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                                         \u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_capabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                                         service_log_path, service, keep_alive)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import glob\n","import os\n","\n","def merge_excel_files(file_path, file_format, save_path, save_format, columns=None):\n","    merge_df = pd.DataFrame()\n","    file_list = file_list = [f\"{file_path}/{file}\" for file in os.listdir(file_path) if file_format in file]\n","    \n","    for file in file_list:\n","        if file_format == \".xlsx\":\n","            file_df = pd.read_excel(file)\n","        else:\n","            file_df = pd.read_csv(file)\n","        \n","        if columns is None:\n","            columns = file_df.columns\n","            \n","        temp_df = pd.DataFrame(file_df, columns=columns)\n","        \n","        merge_df = merge_df.append(temp_df)\n","        \n","    if save_format == \".xlsx\":\n","        merge_df.to_excel(save_path, index=False)\n","    else:\n","        merge_df.to_csv(save_path, index=False)\n","        \n","\n","if __name__ == \"__main__\":\n","    for keyword in keywords:\n","        merge_excel_files(file_path=f\"/naver_news_article_2022/{keyword}\", file_format=\".xlsx\", \n","                          save_path=f\"/naver_news_article_2022/{keyword}/20220101~20220113_{keyword}_네이버_기사.xlsx\", save_format=\".xlsx\")"],"metadata":{"id":"q-FLhdgZVu11","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1648695566898,"user_tz":-540,"elapsed":380,"user":{"displayName":"이병규컴퓨터공학과","userId":"10470548857511681519"}},"outputId":"b272667d-5c02-4dd3-c918-4be7b6ec7b96"},"execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-e70d7ecd9be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         merge_excel_files(file_path=f\"/naver_news_article_2022/{keyword}\", file_format=\".xlsx\", \n\u001b[0;32m---> 31\u001b[0;31m                           save_path=f\"/naver_news_article_2022/{keyword}/20220101~20220113_{keyword}_네이버_기사.xlsx\", save_format=\".xlsx\")\n\u001b[0m","\u001b[0;32m<ipython-input-11-e70d7ecd9be1>\u001b[0m in \u001b[0;36mmerge_excel_files\u001b[0;34m(file_path, file_format, save_path, save_format, columns)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmerge_excel_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmerge_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{file_path}/{file}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile_format\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/naver_news_article_2022/틴더'"]}]}]}